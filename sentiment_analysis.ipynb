{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZAETt7KqjL1K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re,string\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras import layers,models\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, MaxPooling1D, Conv1D, Flatten , LSTM ,Dropout,Bidirectional\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.regularizers import l2\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8KV0S9byjW-Y"
   },
   "outputs": [],
   "source": [
    "tweets=pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "uaL0BkX1Unqa",
    "outputId": "f16b4e3a-2616-43ec-e539-9efe433b4321"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0               neutral                @VirginAmerica What @dhepburn said.\n",
       "1              positive  @VirginAmerica plus you've added commercials t...\n",
       "2               neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3              negative  @VirginAmerica it's really aggressive to blast...\n",
       "4              negative  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635          positive  @AmericanAir thank you we got on a different f...\n",
       "14636          negative  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637           neutral  @AmericanAir Please bring American Airlines to...\n",
       "14638          negative  @AmericanAir you have my money, you change my ...\n",
       "14639           neutral  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new= tweets[['airline_sentiment','text']]\n",
    "tweets_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "o2tJgtZs_K2E"
   },
   "outputs": [],
   "source": [
    "def depure_data(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What said.',\n",
       " 'plus youve added commercials to the experience... tacky.',\n",
       " 'I didnt today... Must mean I need to take another trip!',\n",
       " 'its really aggressive to blast obnoxious \"entertainment\" in your guests faces &amp; they have little recourse',\n",
       " 'and its a really big bad thing about it']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "#Splitting pd.Series to list\n",
    "data_to_list = tweets_new['text'].values\n",
    "for i in range(len(data_to_list)):\n",
    "    temp.append(depure_data(data_to_list[i]))\n",
    "list(temp[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REx6nMIlpjVI",
    "outputId": "d58a124b-e124-41cc-f39d-95a5ecdb40f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'said'], ['plus', 'youve', 'added', 'commercials', 'to', 'the', 'experience', 'tacky'], ['didnt', 'today', 'must', 'mean', 'need', 'to', 'take', 'another', 'trip'], ['its', 'really', 'aggressive', 'to', 'blast', 'obnoxious', 'entertainment', 'in', 'your', 'guests', 'faces', 'amp', 'they', 'have', 'little', 'recourse'], ['and', 'its', 'really', 'big', 'bad', 'thing', 'about', 'it'], ['seriously', 'would', 'pay', 'flight', 'for', 'seats', 'that', 'didnt', 'have', 'this', 'playing', 'its', 'really', 'the', 'only', 'bad', 'thing', 'about', 'flying', 'va'], ['yes', 'nearly', 'every', 'time', 'fly', 'vx', 'this', 'ear', 'worm', 'won', 'go', 'away'], ['really', 'missed', 'prime', 'opportunity', 'for', 'men', 'without', 'hats', 'parody', 'there'], ['well', 'didnt', 'but', 'now', 'do'], ['it', 'was', 'amazing', 'and', 'arrived', 'an', 'hour', 'early', 'youre', 'too', 'good', 'to', 'me']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "\n",
    "data_words = list(sent_to_words(temp))\n",
    "\n",
    "print(data_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hxp9tQCDEDfy",
    "outputId": "d965218e-3d1f-46a2-b0b7-c205336fc10a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what said', 'plus youve added commercials to the experience tacky', 'didnt today must mean need to take another trip', 'its really aggressive to blast obnoxious entertainment in your guests faces amp they have little recourse', 'and its really big bad thing about it']\n"
     ]
    }
   ],
   "source": [
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)\n",
    "\n",
    "data = []\n",
    "for i in range(len(data_words)):\n",
    "    data.append(detokenize(data_words[i]))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "tweets_new.airline_sentiment.loc[tweets_new['airline_sentiment'] == 'neutral']=0\n",
    "tweets_new.airline_sentiment.loc[tweets_new['airline_sentiment'] == 'negative']=1\n",
    "tweets_new.airline_sentiment.loc[tweets_new['airline_sentiment'] == 'positive']=2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>2</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0                     0                @VirginAmerica What @dhepburn said.\n",
       "1                     2  @VirginAmerica plus you've added commercials t...\n",
       "2                     0  @VirginAmerica I didn't today... Must mean I n...\n",
       "3                     1  @VirginAmerica it's really aggressive to blast...\n",
       "4                     1  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635                 2  @AmericanAir thank you we got on a different f...\n",
       "14636                 1  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637                 0  @AmericanAir Please bring American Airlines to...\n",
       "14638                 1  @AmericanAir you have my money, you change my ...\n",
       "14639                 0  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "81LuLyzNEDX6"
   },
   "outputs": [],
   "source": [
    "y = tweets_new['airline_sentiment'].values     \n",
    "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ucpzpf6cEDUB",
    "outputId": "0845e97c-76d1-462e-8a70-8e87b7e23c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    0   51  209]\n",
      " [   0    0    0 ...    1    2  188]\n",
      " [   0    0    0 ...  140  135  177]\n",
      " ...\n",
      " [   0    0    0 ...  432  236    1]\n",
      " [   0    0    0 ...  116    8 2494]\n",
      " [   0    0    0 ...    2  166    5]]\n"
     ]
    }
   ],
   "source": [
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNNdKO-bEDOJ",
    "outputId": "61439c91-2f1b-4502-bb0b-95ed4570bf70"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets,labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "NRix_Qeq8oVm"
   },
   "outputs": [],
   "source": [
    "embedding_dim=150\n",
    "\n",
    "model1 = Sequential([         \n",
    "    Embedding(max_words,embedding_dim, input_length= max_len),\n",
    "    Conv1D(filters=64,kernel_size=8, activation='relu'),\n",
    "    MaxPooling1D(),\n",
    "    Conv1D(filters=32,kernel_size=4, activation='relu'),#, bias_regularizer=l2(0.01)),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(10,activation='relu',kernel_regularizer='l1'),\n",
    "    Dense(3,activation='softmax')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "enoyhqnl_MKe"
   },
   "outputs": [],
   "source": [
    "model1.compile(loss= tf.keras.losses.CategoricalCrossentropy(),optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "jn-_O9YrCtWH",
    "outputId": "6385fc43-2cdc-45a5-8d88-458266519453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "344/344 - 10s - loss: 1.1708 - accuracy: 0.6597\n",
      "Epoch 2/8\n",
      "344/344 - 10s - loss: 0.6747 - accuracy: 0.7072\n",
      "Epoch 3/8\n",
      "344/344 - 10s - loss: 0.6019 - accuracy: 0.7270\n",
      "Epoch 4/8\n",
      "344/344 - 10s - loss: 0.5264 - accuracy: 0.7781\n",
      "Epoch 5/8\n",
      "344/344 - 10s - loss: 0.4435 - accuracy: 0.8374\n",
      "Epoch 6/8\n",
      "344/344 - 11s - loss: 0.3764 - accuracy: 0.8716\n",
      "Epoch 7/8\n",
      "344/344 - 11s - loss: 0.3110 - accuracy: 0.8951\n",
      "Epoch 8/8\n",
      "344/344 - 11s - loss: 0.2664 - accuracy: 0.9116\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X_train,y_train,epochs=8,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w2QgEd3SDFa7",
    "outputId": "15b24d07-bbcf-4908-ef22-96b1101b6980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.420765\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model1.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "344/344 - 39s - loss: 1.1531 - accuracy: 0.6600 - 39s/epoch - 113ms/step\n",
      "Epoch 2/8\n",
      "344/344 - 36s - loss: 0.6506 - accuracy: 0.7299 - 36s/epoch - 104ms/step\n",
      "Epoch 3/8\n",
      "344/344 - 36s - loss: 0.5378 - accuracy: 0.7980 - 36s/epoch - 106ms/step\n",
      "Epoch 4/8\n",
      "344/344 - 36s - loss: 0.4330 - accuracy: 0.8454 - 36s/epoch - 106ms/step\n",
      "Epoch 5/8\n",
      "344/344 - 37s - loss: 0.3347 - accuracy: 0.8821 - 37s/epoch - 106ms/step\n",
      "Epoch 6/8\n",
      "344/344 - 36s - loss: 0.2704 - accuracy: 0.9087 - 36s/epoch - 105ms/step\n",
      "Epoch 7/8\n",
      "344/344 - 35s - loss: 0.2298 - accuracy: 0.9230 - 35s/epoch - 103ms/step\n",
      "Epoch 8/8\n",
      "344/344 - 37s - loss: 0.2056 - accuracy: 0.9301 - 37s/epoch - 106ms/step\n"
     ]
    }
   ],
   "source": [
    "embedding_dim=300\n",
    "\n",
    "model = Sequential([         \n",
    "    Embedding(max_words,embedding_dim, input_length= max_len),\n",
    "    Conv1D(filters=64,kernel_size=8, activation='relu'),\n",
    "    MaxPooling1D(),\n",
    "    Conv1D(filters=32,kernel_size=4, activation='relu'),#, bias_regularizer=l2(0.01)),\n",
    "    MaxPooling1D(),\n",
    "    Flatten(),\n",
    "    Dense(10,activation='relu',kernel_regularizer='l1'),\n",
    "    Dense(3,activation='softmax')\n",
    "\n",
    "])\n",
    "model.compile(loss= tf.keras.losses.CategoricalCrossentropy(),optimizer='adam',metrics=['accuracy'])\n",
    "history = model.fit(X_train,y_train,epochs=8,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.486341\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0               neutral                @VirginAmerica What @dhepburn said.\n",
       "1              positive  @VirginAmerica plus you've added commercials t...\n",
       "2               neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3              negative  @VirginAmerica it's really aggressive to blast...\n",
       "4              negative  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635          positive  @AmericanAir thank you we got on a different f...\n",
       "14636          negative  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637           neutral  @AmericanAir Please bring American Airlines to...\n",
       "14638          negative  @AmericanAir you have my money, you change my ...\n",
       "14639           neutral  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets=pd.read_csv('Tweets.csv')\n",
    "tweets_new= tweets[['airline_sentiment','text']]\n",
    "tweets_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>2</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0                     0                @VirginAmerica What @dhepburn said.\n",
       "1                     2  @VirginAmerica plus you've added commercials t...\n",
       "2                     0  @VirginAmerica I didn't today... Must mean I n...\n",
       "3                     1  @VirginAmerica it's really aggressive to blast...\n",
       "4                     1  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635                 2  @AmericanAir thank you we got on a different f...\n",
       "14636                 1  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637                 0  @AmericanAir Please bring American Airlines to...\n",
       "14638                 1  @AmericanAir you have my money, you change my ...\n",
       "14639                 0  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new.airline_sentiment.loc[tweets_new['airline_sentiment'] == 'neutral']=0\n",
    "tweets_new.airline_sentiment.loc[tweets_new['airline_sentiment'] == 'negative']=1\n",
    "tweets_new.airline_sentiment.loc[tweets_new['airline_sentiment'] == 'positive']=2   \n",
    "tweets_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tweets_new['airline_sentiment'].values     \n",
    "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('glove.6B\\glove.6B.300d.txt', binary = False,no_header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32368 , -0.14921 , -0.47491 ,  0.11804 ,  0.34319 ,  0.2301  ,\n",
       "       -0.20581 ,  0.43724 ,  0.077597, -2.5859  , -0.13203 ,  0.06049 ,\n",
       "       -0.36986 ,  0.41528 ,  0.47718 , -0.19045 ,  0.10687 , -0.4391  ,\n",
       "        0.41823 ,  0.072872], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economy_vec = model['economy']\n",
    "economy_vec[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits \n",
    "stop=set(stopwords.words('english'))\n",
    "def tweets_cleaning(x, remove_emojis=True, remove_stop_words=True):\n",
    "    \"\"\"Apply function to a \"\"\"\n",
    "    x = x.lower().strip()\n",
    "    # romove urls\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    x = url.sub(r'',x)\n",
    "    # remove html tags\n",
    "    html = re.compile(r'<.*?>')\n",
    "    x = html.sub(r'',x)\n",
    "    # remove punctuation\n",
    "    operator = str.maketrans('','',string.punctuation) #????\n",
    "    x = x.translate(operator)\n",
    "    # remove digits\n",
    "    remove_digits = str.maketrans('', '', digits) \n",
    "    x = ' '.join([i.translate(remove_digits) for i in x.split()])\n",
    "    \n",
    "    if remove_emojis:\n",
    "        x = x.encode('ascii', 'ignore').decode('utf8').strip()\n",
    "    if remove_stop_words:\n",
    "        x = ' '.join([word for word in x.split(' ') if word not in stop])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_29548/2709407075.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_new['clean_text'] = tweets_new['text'].apply(tweets_cleaning)\n"
     ]
    }
   ],
   "source": [
    "tweets_new['clean_text'] = tweets_new['text'].apply(tweets_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>virginamerica plus youve added commercials exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>virginamerica didnt today must mean need take ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>2</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>americanair thank got different flight chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>americanair leaving  minutes late flight warni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>americanair please bring american airlines bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>americanair money change flight dont answer ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>americanair  ppl need  know many seats next fl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text  \\\n",
       "0                     0                @VirginAmerica What @dhepburn said.   \n",
       "1                     2  @VirginAmerica plus you've added commercials t...   \n",
       "2                     0  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3                     1  @VirginAmerica it's really aggressive to blast...   \n",
       "4                     1  @VirginAmerica and it's a really big bad thing...   \n",
       "...                 ...                                                ...   \n",
       "14635                 2  @AmericanAir thank you we got on a different f...   \n",
       "14636                 1  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637                 0  @AmericanAir Please bring American Airlines to...   \n",
       "14638                 1  @AmericanAir you have my money, you change my ...   \n",
       "14639                 0  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "                                              clean_text  \n",
       "0                            virginamerica dhepburn said  \n",
       "1      virginamerica plus youve added commercials exp...  \n",
       "2      virginamerica didnt today must mean need take ...  \n",
       "3      virginamerica really aggressive blast obnoxiou...  \n",
       "4                     virginamerica really big bad thing  \n",
       "...                                                  ...  \n",
       "14635     americanair thank got different flight chicago  \n",
       "14636  americanair leaving  minutes late flight warni...  \n",
       "14637  americanair please bring american airlines bla...  \n",
       "14638  americanair money change flight dont answer ph...  \n",
       "14639  americanair  ppl need  know many seats next fl...  \n",
       "\n",
       "[14640 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [airline_sentiment, text, clean_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new[tweets_new['clean_text'].apply(len)<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets_new['clean_text'],labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "lst_text2seq= tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(lst_text2seq, \n",
    "                    maxlen=150, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "lst_text2seq2= tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(lst_text2seq2, \n",
    "                    maxlen=150, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "i=0\n",
    "for word in model.index_to_key:\n",
    "    if word in word_index.keys():\n",
    "        embedding_vector = model[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11293, 300)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_with_w2v():\n",
    "    input_layer = layers.Input((150, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer_1 = Embedding(len(tokenizer.word_index)+1, 300,weights=[embedding_matrix],trainable=False)(input_layer)\n",
    "    embedding_layer_2 = layers.SpatialDropout1D(0.5)(embedding_layer_1)\n",
    "    conv_1 = Conv1D(filters=32,kernel_size=8, activation='relu')(embedding_layer_2)\n",
    "    max_pool_1 = MaxPooling1D()(conv_1)\n",
    "    conv_2 = Conv1D(filters=16,kernel_size=4, activation='relu')(max_pool_1)\n",
    "    max_pool_2 = MaxPooling1D()(conv_2)\n",
    "    flat = Flatten()(max_pool_2)\n",
    "    dense_1 = Dense(10,activation='relu',kernel_regularizer='l1')(flat)\n",
    "    dense_2 = Dense(3,activation='softmax')(dense_1)\n",
    "    \n",
    "    # Compile the model\n",
    "    model_ = models.Model(inputs=input_layer, outputs=dense_2)\n",
    "    model_.compile(loss= tf.keras.losses.CategoricalCrossentropy(),optimizer='adam',metrics=['accuracy'])\n",
    "    return model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "344/344 - 8s - loss: 1.3750 - accuracy: 0.6323 - 8s/epoch - 22ms/step\n",
      "Epoch 2/16\n",
      "344/344 - 7s - loss: 0.8309 - accuracy: 0.6487 - 7s/epoch - 21ms/step\n",
      "Epoch 3/16\n",
      "344/344 - 7s - loss: 0.7966 - accuracy: 0.6576 - 7s/epoch - 21ms/step\n",
      "Epoch 4/16\n",
      "344/344 - 7s - loss: 0.7718 - accuracy: 0.6657 - 7s/epoch - 21ms/step\n",
      "Epoch 5/16\n",
      "344/344 - 7s - loss: 0.7478 - accuracy: 0.6700 - 7s/epoch - 21ms/step\n",
      "Epoch 6/16\n",
      "344/344 - 7s - loss: 0.7160 - accuracy: 0.6884 - 7s/epoch - 21ms/step\n",
      "Epoch 7/16\n",
      "344/344 - 7s - loss: 0.6901 - accuracy: 0.7075 - 7s/epoch - 21ms/step\n",
      "Epoch 8/16\n",
      "344/344 - 7s - loss: 0.6639 - accuracy: 0.7266 - 7s/epoch - 21ms/step\n",
      "Epoch 9/16\n",
      "344/344 - 7s - loss: 0.6406 - accuracy: 0.7349 - 7s/epoch - 21ms/step\n",
      "Epoch 10/16\n",
      "344/344 - 7s - loss: 0.6091 - accuracy: 0.7535 - 7s/epoch - 21ms/step\n",
      "Epoch 11/16\n",
      "344/344 - 7s - loss: 0.5879 - accuracy: 0.7639 - 7s/epoch - 21ms/step\n",
      "Epoch 12/16\n",
      "344/344 - 7s - loss: 0.5614 - accuracy: 0.7748 - 7s/epoch - 22ms/step\n",
      "Epoch 13/16\n",
      "344/344 - 7s - loss: 0.5490 - accuracy: 0.7845 - 7s/epoch - 21ms/step\n",
      "Epoch 14/16\n",
      "344/344 - 7s - loss: 0.5321 - accuracy: 0.7868 - 7s/epoch - 21ms/step\n",
      "Epoch 15/16\n",
      "344/344 - 7s - loss: 0.5049 - accuracy: 0.8006 - 7s/epoch - 21ms/step\n",
      "Epoch 16/16\n",
      "344/344 - 7s - loss: 0.4919 - accuracy: 0.8058 - 7s/epoch - 22ms/step\n"
     ]
    }
   ],
   "source": [
    "model_with_w2v=model_with_w2v()\n",
    "history2 = model_with_w2v.fit(X_train,y_train,epochs=16,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.726777\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model_with_w2v.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lstm version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=pd.read_csv('Tweets.csv')\n",
    "tweets_new= tweets[['airline_sentiment','text']]\n",
    "def depure_data(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What said.',\n",
       " 'plus youve added commercials to the experience... tacky.',\n",
       " 'I didnt today... Must mean I need to take another trip!',\n",
       " 'its really aggressive to blast obnoxious \"entertainment\" in your guests faces &amp; they have little recourse',\n",
       " 'and its a really big bad thing about it']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "#Splitting pd.Series to list\n",
    "data_to_list = tweets_new['text'].values\n",
    "for i in range(len(data_to_list)):\n",
    "    temp.append(depure_data(data_to_list[i]))\n",
    "list(temp[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'said'], ['plus', 'youve', 'added', 'commercials', 'to', 'the', 'experience', 'tacky'], ['didnt', 'today', 'must', 'mean', 'need', 'to', 'take', 'another', 'trip'], ['its', 'really', 'aggressive', 'to', 'blast', 'obnoxious', 'entertainment', 'in', 'your', 'guests', 'faces', 'amp', 'they', 'have', 'little', 'recourse'], ['and', 'its', 'really', 'big', 'bad', 'thing', 'about', 'it'], ['seriously', 'would', 'pay', 'flight', 'for', 'seats', 'that', 'didnt', 'have', 'this', 'playing', 'its', 'really', 'the', 'only', 'bad', 'thing', 'about', 'flying', 'va'], ['yes', 'nearly', 'every', 'time', 'fly', 'vx', 'this', 'ear', 'worm', 'won', 'go', 'away'], ['really', 'missed', 'prime', 'opportunity', 'for', 'men', 'without', 'hats', 'parody', 'there'], ['well', 'didnt', 'but', 'now', 'do'], ['it', 'was', 'amazing', 'and', 'arrived', 'an', 'hour', 'early', 'youre', 'too', 'good', 'to', 'me']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "        \n",
    "\n",
    "data_words = list(sent_to_words(temp))\n",
    "\n",
    "print(data_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what said', 'plus youve added commercials to the experience tacky', 'didnt today must mean need to take another trip', 'its really aggressive to blast obnoxious entertainment in your guests faces amp they have little recourse', 'and its really big bad thing about it']\n"
     ]
    }
   ],
   "source": [
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)\n",
    "\n",
    "data = []\n",
    "for i in range(len(data_words)):\n",
    "    data.append(detokenize(data_words[i]))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "tweets_new.airline_sentiment.loc[tweets_new['airline_sentiment'] == 'neutral']=0\n",
    "tweets_new.airline_sentiment.loc[tweets_new['airline_sentiment'] == 'negative']=1\n",
    "tweets_new.airline_sentiment.loc[tweets_new['airline_sentiment'] == 'positive']=2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>2</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>1</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0                     0                @VirginAmerica What @dhepburn said.\n",
       "1                     2  @VirginAmerica plus you've added commercials t...\n",
       "2                     0  @VirginAmerica I didn't today... Must mean I n...\n",
       "3                     1  @VirginAmerica it's really aggressive to blast...\n",
       "4                     1  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635                 2  @AmericanAir thank you we got on a different f...\n",
       "14636                 1  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637                 0  @AmericanAir Please bring American Airlines to...\n",
       "14638                 1  @AmericanAir you have my money, you change my ...\n",
       "14639                 0  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tweets_new['airline_sentiment'].values     \n",
    "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    0   51  209]\n",
      " [   0    0    0 ...    1    2  188]\n",
      " [   0    0    0 ...  140  135  177]\n",
      " ...\n",
      " [   0    0    0 ...  432  236    1]\n",
      " [   0    0    0 ...  116    8 2494]\n",
      " [   0    0    0 ...    2  166    5]]\n"
     ]
    }
   ],
   "source": [
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tweets,labels, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "344/344 - 160s - loss: 1.1009 - accuracy: 0.6608 - 160s/epoch - 466ms/step\n",
      "Epoch 2/4\n",
      "344/344 - 414s - loss: 0.7029 - accuracy: 0.7447 - 414s/epoch - 1s/step\n",
      "Epoch 3/4\n",
      "344/344 - 510s - loss: 0.6067 - accuracy: 0.7825 - 510s/epoch - 1s/step\n",
      "Epoch 4/4\n",
      "344/344 - 501s - loss: 0.5411 - accuracy: 0.8049 - 501s/epoch - 1s/step\n"
     ]
    }
   ],
   "source": [
    "embedding_dim=300\n",
    "model_lstm_1 = Sequential([         \n",
    "    Embedding(max_words,embedding_dim, input_length= max_len),\n",
    "    LSTM(35,dropout=0.5, recurrent_dropout=0.2,return_sequences=False),\n",
    "    Dense(10,activation='relu',kernel_regularizer='l1'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3,activation='softmax')\n",
    "\n",
    "])\n",
    "model_lstm_1.compile(loss= tf.keras.losses.CategoricalCrossentropy(),optimizer='adam',metrics=['accuracy'])\n",
    "history_lstm_1 = model_lstm_1.fit(X_train,y_train,epochs=4,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 78.961748\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model_lstm_1.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "344/344 - 78s - loss: 0.9811 - accuracy: 0.6496 - 78s/epoch - 228ms/step\n",
      "Epoch 2/10\n",
      "344/344 - 74s - loss: 0.7173 - accuracy: 0.7189 - 74s/epoch - 215ms/step\n",
      "Epoch 3/10\n",
      "344/344 - 74s - loss: 0.6142 - accuracy: 0.7563 - 74s/epoch - 215ms/step\n",
      "Epoch 4/10\n",
      "344/344 - 75s - loss: 0.5432 - accuracy: 0.7968 - 75s/epoch - 217ms/step\n",
      "Epoch 5/10\n",
      "344/344 - 74s - loss: 0.4840 - accuracy: 0.8339 - 74s/epoch - 216ms/step\n",
      "Epoch 6/10\n",
      "344/344 - 74s - loss: 0.4203 - accuracy: 0.8669 - 74s/epoch - 216ms/step\n",
      "Epoch 7/10\n",
      "344/344 - 74s - loss: 0.3809 - accuracy: 0.8904 - 74s/epoch - 216ms/step\n",
      "Epoch 8/10\n",
      "344/344 - 74s - loss: 0.3477 - accuracy: 0.9067 - 74s/epoch - 216ms/step\n",
      "Epoch 9/10\n",
      "344/344 - 74s - loss: 0.3165 - accuracy: 0.9168 - 74s/epoch - 216ms/step\n",
      "Epoch 10/10\n",
      "344/344 - 74s - loss: 0.2959 - accuracy: 0.9258 - 74s/epoch - 216ms/step\n"
     ]
    }
   ],
   "source": [
    "embedding_dim=300\n",
    "model_multi_lstm = Sequential([         \n",
    "    Embedding(max_words,embedding_dim, input_length= max_len),\n",
    "    LSTM(10, return_sequences=True),\n",
    "    LSTM(10,return_sequences=True),\n",
    "    LSTM(10,dropout=0.2, recurrent_dropout=0.2,return_sequences=False),\n",
    "    Dense(10,activation='relu',kernel_regularizer='l1'),\n",
    "    Dropout(0.4),\n",
    "    Dense(3,activation='softmax')\n",
    "\n",
    "])\n",
    "model_multi_lstm.compile(loss= tf.keras.losses.CategoricalCrossentropy(),optimizer='adam',metrics=['accuracy'])\n",
    "history_lstm_multi = model_multi_lstm.fit(X_train,y_train,epochs=10,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 78.989071\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model_multi_lstm.evaluate(X_test,y_test,verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_20644/4136055292.py:21: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  lstm_model = KerasClassifier(build_fn=multi_lstm,verbose=0)\n"
     ]
    }
   ],
   "source": [
    "def multi_lstm(optimizer='adam',\n",
    "               dropout1=0.5,\n",
    "               dropout2=0.2,\n",
    "               recurrent_dropout=0.2,\n",
    "               unit1=10,\n",
    "               unit2=10,\n",
    "               ):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words,300, input_length= max_len))\n",
    "    model.add(LSTM(unit1,dropout=dropout1, recurrent_dropout=recurrent_dropout, return_sequences=True))\n",
    "    model.add(LSTM(unit2,return_sequences=True))\n",
    "    model.add(LSTM(unit2,dropout=dropout2, recurrent_dropout=recurrent_dropout,return_sequences=False))\n",
    "    model.add(Dense(10,activation='relu',kernel_regularizer='l1'))\n",
    "    model.add(Dropout(dropout1))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "    model.compile(loss= tf.keras.losses.CategoricalCrossentropy(),optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "lstm_model = KerasClassifier(build_fn=multi_lstm,verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'optimizer':['adam','adagrad'],\n",
    "    'epochs':[8,10,12,15],\n",
    "    'dropout1':[0.2,0.5,0.7],\n",
    "    'dropout2':[0.2,0.5,0.7],\n",
    "    'recurrent_dropout':[0.2,0.4],\n",
    "    'unit1':[8,10,15,20],\n",
    "    'unit2':[8,10,15,20]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(lstm_model, cv=3, param_grid=param_grid,n_jobs =-1)\n",
    "result=grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "params = result.cv_results_['params']"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sentiment-analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
